{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2df397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_score\n",
    "from preprocess import preprocess_fraud_data\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_auc_score, f1_score, auc, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7aa15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"./data/dataset_balanceado.csv\"\n",
    "df = pd.read_csv(ruta)\n",
    "\n",
    "data = preprocess_fraud_data(df)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c1d35",
   "metadata": {},
   "source": [
    "**Modelos SVM Base (`kernel='linear', 'rbf'`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8de88165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0      1  accuracy    macro avg  weighted avg\n",
      "precision     0.909091    0.0  0.909091     0.454545      0.826446\n",
      "recall        1.000000    0.0  0.909091     0.500000      0.909091\n",
      "f1-score      0.952381    0.0  0.909091     0.476190      0.865801\n",
      "support    6000.000000  600.0  0.909091  6600.000000   6600.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[6000    0]\n",
      " [ 600    0]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0      1  accuracy    macro avg  weighted avg\n",
      "precision     0.909091    0.0  0.909091     0.454545      0.826446\n",
      "recall        1.000000    0.0  0.909091     0.500000      0.909091\n",
      "f1-score      0.952381    0.0  0.909091     0.476190      0.865801\n",
      "support    2000.000000  200.0  0.909091  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[2000    0]\n",
      " [ 200    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_lineal = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "svm_lineal.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_lineal, X_train, y_train, X_val, y_val, train=True)\n",
    "print_score(svm_lineal, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dca79af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0      1  accuracy    macro avg  weighted avg\n",
      "precision     0.909091    0.0  0.909091     0.454545      0.826446\n",
      "recall        1.000000    0.0  0.909091     0.500000      0.909091\n",
      "f1-score      0.952381    0.0  0.909091     0.476190      0.865801\n",
      "support    6000.000000  600.0  0.909091  6600.000000   6600.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[6000    0]\n",
      " [ 600    0]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0      1  accuracy    macro avg  weighted avg\n",
      "precision     0.909091    0.0  0.909091     0.454545      0.826446\n",
      "recall        1.000000    0.0  0.909091     0.500000      0.909091\n",
      "f1-score      0.952381    0.0  0.909091     0.476190      0.865801\n",
      "support    2000.000000  200.0  0.909091  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[2000    0]\n",
      " [ 200    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm, X_train, y_train, X_val, y_val, train=True)\n",
    "print_score(svm, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d73e7",
   "metadata": {},
   "source": [
    "> Tanto los modelos SVM con kernel lineal como con kernel RBF, sin ningún manejo de desequilibrio de clases, no logran identificar ninguna transacción fraudulenta, clasifica todas las instancias como la clase mayoritaria (transacciones legítimas), lo que lleva a un alto puntaje de exactitud (accuracy) que es engañoso debido al desequilibrio de clases, lo cual confirma que es necesario aplicar técnicas para abordar el desequilibrio de clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29dea85",
   "metadata": {},
   "source": [
    "**Modelos con `class_weight='balanced'`**\n",
    "\n",
    "Se entrena SVM con ajuste de pesos automáticos, class_weight='balanced' le asigna un mayor peso a las clases minoritarias de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62885f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 51.30%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.919073    0.101038   0.51303     0.510056      0.844707\n",
      "recall        0.509167    0.551667   0.51303     0.530417      0.513030\n",
      "f1-score      0.655298    0.170795   0.51303     0.413046      0.611252\n",
      "support    6000.000000  600.000000   0.51303  6600.000000   6600.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3055 2945]\n",
      " [ 269  331]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 48.32%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.910561    0.092254  0.483182     0.501408      0.836170\n",
      "recall        0.478500    0.530000  0.483182     0.504250      0.483182\n",
      "f1-score      0.627335    0.157153  0.483182     0.392244      0.584591\n",
      "support    2000.000000  200.000000  0.483182  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 957 1043]\n",
      " [  94  106]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_base = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "\n",
    "svm_base.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_base, X_train, y_train, X_val, y_val, train=True)\n",
    "print_score(svm_base, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34227037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 68.42%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.971353    0.196648  0.684242     0.584000      0.900925\n",
      "recall        0.672500    0.801667  0.684242     0.737083      0.684242\n",
      "f1-score      0.794761    0.315824  0.684242     0.555292      0.751221\n",
      "support    6000.000000  600.000000  0.684242  6600.000000   6600.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4035 1965]\n",
      " [ 119  481]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 60.23%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.906137    0.085890  0.602273     0.496013      0.831569\n",
      "recall        0.627500    0.350000  0.602273     0.488750      0.602273\n",
      "f1-score      0.741507    0.137931  0.602273     0.439719      0.686636\n",
      "support    2000.000000  200.000000  0.602273  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1255  745]\n",
      " [ 130   70]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_base = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "\n",
    "svm_base.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_base, X_train, y_train, X_val, y_val, train=True)\n",
    "print_score(svm_base, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cdb39d",
   "metadata": {},
   "source": [
    "> El modelo SVM con `kernel='linear'`, al incorporar el hiperparámetro `class_weight='balanced'`, logra mejorar la detección de la clase minoritaria (fraude), pero a costa de incrementar significativamente los falsos positivos, esto ocurre porque al balancear los pesos de las clases, el modelo recibe una penalización mucho mayor por clasificar un fraude como legítimo, por lo que tiende a expandir la frontera de decisión hacia la clase mayoritaria para capturar más fraudes, lo cual da como resultado que algunas transacciones legítimas que están cerca de la frontera, donde la función de decisión se aproxima al umbral por defecto (0.5) son clasificadas erróneamente como fraude.\n",
    ">\n",
    "> Este mismo comportamiento se observa en el modelo SVM con `kernel='rbf'`, aunque con algunas diferencias, el SVM lineal, al tener una frontera de decisión más simple, tiende a sobrecompensar más agresivamente el desbalance, lo que le permite identificar un mayor número de fraudes (mayor recall), pero también genera más falsos positivos que el modelo con kernel RBF, por otro lado, el SVM RBF, al modelar una frontera más compleja y no lineal, logra un mejor compromiso entre precisión y recall, evitando clasificar tan fácilmente como fraude a observaciones legítimas cercanas a la frontera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48eb1c6",
   "metadata": {},
   "source": [
    "**Undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df91b828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución original: [6000  600]\n",
      "Distribución después de undersampling: [600 600]\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 55.08%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.549433    0.552316  0.550833     0.550874      0.550874\n",
      "recall       0.565000    0.536667  0.550833     0.550833      0.550833\n",
      "f1-score     0.557108    0.544379  0.550833     0.550743      0.550743\n",
      "support    600.000000  600.000000  0.550833  1200.000000   1200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[339 261]\n",
      " [278 322]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 48.59%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.912631    0.094159  0.485909     0.503395      0.838224\n",
      "recall        0.480500    0.540000  0.485909     0.510250      0.485909\n",
      "f1-score      0.629545    0.160356  0.485909     0.394951      0.586891\n",
      "support    2000.000000  200.000000  0.485909  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 961 1039]\n",
      " [  92  108]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución original:\", np.bincount(y_train))\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribución después de undersampling:\", np.bincount(y_under))\n",
    "\n",
    "model_under = SVC(kernel='linear', random_state=42)\n",
    "model_under.fit(X_under, y_under)\n",
    "\n",
    "print_score(model_under, X_under, y_under, X_val, y_val, train=True)\n",
    "print_score(model_under, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749b26c",
   "metadata": {},
   "source": [
    "> Se aplicó `RandomUnderSampler` para balancear las clases en el conjunto de entrenamiento, reduciendo la clase mayoritaria (transacciones legítimas) a 600 muestras, igualando así la clase minoritaria (fraudes), aunque este enfoque mejora la simetría del conjunto de entrenamiento y permite al modelo aprender de manera equitativa ambas clases, también elimina una gran cantidad de información relevante de la clase mayoritaria, lo cual perjudica la generalización y provoca que en validación genere muchos falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa514f",
   "metadata": {},
   "source": [
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b6427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución después de SMOTE: IsFraud\n",
      "0    6000\n",
      "1    6000\n",
      "Name: count, dtype: int64\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 61.97%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy     macro avg  weighted avg\n",
      "precision     0.637495     0.605931  0.619667      0.621713      0.621713\n",
      "recall        0.554833     0.684500  0.619667      0.619667      0.619667\n",
      "f1-score      0.593299     0.642824  0.619667      0.618061      0.618061\n",
      "support    6000.000000  6000.000000  0.619667  12000.000000  12000.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3329 2671]\n",
      " [1893 4107]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 54.77%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.910875    0.093142  0.547727     0.502009      0.836536\n",
      "recall        0.557000    0.455000  0.547727     0.506000      0.547727\n",
      "f1-score      0.691281    0.154630  0.547727     0.422956      0.642495\n",
      "support    2000.000000  200.000000  0.547727  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[1114  886]\n",
      " [ 109   91]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribución después de SMOTE:\", y_smote.value_counts())\n",
    "\n",
    "model_smote = SVC(kernel='linear', random_state=42)\n",
    "model_smote.fit(X_smote, y_smote)\n",
    "\n",
    "print_score(model_smote, X_smote, y_smote, X_val, y_val, train=True)\n",
    "print_score(model_smote, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3d04b",
   "metadata": {},
   "source": [
    "> Se aplicó la técnica de oversampling SMOTE para generar ejemplos sintéticos de la clase minoritaria (fraudes), obteniendo un conjunto de entrenamiento balanceado con 6000 ejemplos de cada clase, durante el entrenamiento el modelo logró un desempeño balanceado, lo que indica que el modelo pudo aprender patrones representativos de la clase fraude a partir de los ejemplos sintéticos, sin embargo, al evaluar el modelo sobre un conjunto de validación con la distribución real de clases (altamente desbalanceada), se observó una caída en la precisión hacia la clase de fraude, debido a la cantidad de falsos positivos (886), esto se debe a que el modelo fue entrenado con un conjunto balanceado y por tanto tiende a sobreestimar la presencia de fraudes en el conjunto de validación, donde en realidad los fraudes son mucho menos frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfea6cf",
   "metadata": {},
   "source": [
    "**Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f5a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución original: [6000  600]\n",
      "Distribución después de oversampling: [6000 6000]\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 53.23%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy     macro avg  weighted avg\n",
      "precision     0.533368     0.531205   0.53225      0.532286      0.532286\n",
      "recall        0.515500     0.549000   0.53225      0.532250      0.532250\n",
      "f1-score      0.524282     0.539956   0.53225      0.532119      0.532119\n",
      "support    6000.000000  6000.000000   0.53225  12000.000000  12000.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3093 2907]\n",
      " [2706 3294]]\n",
      "\n",
      "Validation Result:\n",
      "================================================\n",
      "Accuracy Score: 48.73%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0           1  accuracy    macro avg  weighted avg\n",
      "precision     0.910546    0.092267  0.487273     0.501407      0.836157\n",
      "recall        0.483500    0.525000  0.487273     0.504250      0.487273\n",
      "f1-score      0.631613    0.156951  0.487273     0.394282      0.588462\n",
      "support    2000.000000  200.000000  0.487273  2200.000000   2200.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 967 1033]\n",
      " [  95  105]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución original:\", np.bincount(y_train))\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribución después de oversampling:\", np.bincount(y_over))\n",
    "\n",
    "model_over = SVC(kernel='linear', random_state=42)\n",
    "model_over.fit(X_over, y_over)\n",
    "\n",
    "print_score(model_over, X_over, y_over, X_val, y_val, train=True)\n",
    "print_score(model_over, X_train, y_train, X_val, y_val, train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35151012",
   "metadata": {},
   "source": [
    "> Se aplicó `RandomOverSampler` para balancear el conjunto de entrenamiento, duplicando instancias reales de la clase minoritaria (fraudes) hasta igualar el número de transacciones legítimas, esta técnica no genera nuevos patrones, sino que replica observaciones existentes, lo que puede llevar a un sobreajuste leve a ejemplos duplicados, en entrenamiento el modelo mostró un desempeño equilibrado, aunque con métricas más bajas que con SMOTE.\n",
    ">\n",
    "> En validación presentó un comportamiento similar al de `undersampling`, alto número de falsos positivos (1033) y una precisión para la clase fraude muy baja (9.2%), a pesar de mantener un *recall* de (0.525), esto se debe a que el modelo, al haber aprendido con un conjunto artificialmente balanceado, tiende a sobreestimar la probabilidad de fraude cuando se enfrenta a la distribución real desbalanceada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
